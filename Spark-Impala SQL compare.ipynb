{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheatsheet on \"How to use Spark SQL\"\n",
    "\n",
    "\n",
    "   In this notebook, I try to make readable and easy to use reference for [SQL](https://en.wikipedia.org/wiki/SQL) users aiming to explain how to do similar action in [Spark SQL](https://spark.apache.org/docs/2.3.1/api/sql/).  \n",
    "   \n",
    "|Spark     | Impala|\n",
    "|:------:   | :------:|\n",
    "|![Spark](https://spark.apache.org/docs/2.3.1/img/spark-logo-hd.png)| ![Impala](https://impala.apache.org/img/impala-logo.png)|\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "I tried to summerize SQL basic commands and to point out some Spark SQL exclusive statements and compare them with Impala SQL.\n",
    "<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common basic SQL command\n",
    "[W3school](https://www.w3schools.com/sql/default.asp) provided a good tutorial on SQL statements. Here I try to give some useful examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General `SELECT` statement:\n",
    "\n",
    "\n",
    "\n",
    "```sql\n",
    "SELECT column1, column2, ...\n",
    "FROM table_name\n",
    "WHERE condition;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "```sql\n",
    "SELECT purchase_date, product, customer_id\n",
    "FROM my_table\n",
    "WHERE purchase_date > 18700\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate statement (`Group by`)\n",
    "Useful aggregate functions: `count()`, `sum()`, `avg()`\n",
    "```sql\n",
    "SELECT column_name(s)\n",
    "FROM table_name\n",
    "WHERE condition\n",
    "GROUP BY column_name(s)\n",
    "ORDER BY column_name(s) ASC|DESC;;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "```sql\n",
    "SELECT purchase_date, product, customer_id, sum(price)\n",
    "FROM my_table\n",
    "WHERE purchase_date > 18700\n",
    "GROUP BY purchase_date, product, customer_id\n",
    "ORDER BY purchase_date ASC\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select TOP\n",
    "\n",
    "|  TOP X   |   LIMIT X |\n",
    "|:----------|:-----------|\n",
    "|`SELECT TOP number\\|percent column_name(s)` <br> `FROM table_name` <br> `WHERE condition;`|`SELECT column_name(s)` <br> `FROM table_name` <br> `WHERE condition` <br> `LIMIT number;`|\n",
    "|**SQL Server**<br> **Sybase** | **MySQL**<br> **Impala**<br> **Spark** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impala Spark Differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group By Alias\n",
    "\n",
    "**Impala:**\n",
    "\n",
    "```sql\n",
    "SELECT from_unixtime(floor((begin_time + 7*1800)/3600)*3600, 'dd-MMM-yyyy HH:mm') as qdatehour, sum(price)\n",
    "from my_table\n",
    "where product = 'Milk'\n",
    "group by qdatehour\n",
    "```\n",
    "\n",
    "**Spark:**\n",
    "\n",
    "```sql\n",
    "SELECT from_unixtime(BEGIN_TIME, 'dd-MMM-yyyy HH') as qdatehour, sum(price)\n",
    "from my_table\n",
    "where product = 'Milk'\n",
    "group by from_unixtime(BEGIN_TIME, 'dd-MMM-yyyy HH')\n",
    "```\n",
    "\n",
    "\n",
    "Notes:\n",
    "\n",
    "    1- Spark automatically converts unix time to local time, but Impala needs conversion to local time first (+3.5 hours)\n",
    "    \n",
    "    2- in Spark the alias cannot be used in `group by`, but in Impala it is possible.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order By Alias\n",
    "\n",
    "**Impala:**\n",
    "\n",
    "```sql\n",
    "SELECT from_unixtime(floor((begin_time + 7*1800)/3600)*3600, 'dd-MMM-yyyy HH:mm') as qdatehour, sum(price)\n",
    "from my_table\n",
    "where product = 'Milk'\n",
    "group by qdatehour\n",
    "order by qdatehour\n",
    "```\n",
    "\n",
    "**Spark:**\n",
    "\n",
    "```sql\n",
    "SELECT from_unixtime(BEGIN_TIME, 'dd-MMM-yyyy HH') as qdatehour, sum(price)\n",
    "from my_table\n",
    "where product = 'Milk'\n",
    "group by from_unixtime(BEGIN_TIME, 'dd-MMM-yyyy HH')\n",
    "order by qdatehour\n",
    "```\n",
    "\n",
    "#### Using `UNION` and `ORDER BY` together:\n",
    "\n",
    "```sql\n",
    "SELECT from_unixtime(BEGIN_TIME, 'dd-MMM-yyyy HH') as qdatehour, sum(price)\n",
    "from my_table1\n",
    "where product = 'Milk'\n",
    "group by from_unixtime(BEGIN_TIME, 'dd-MMM-yyyy HH')\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT from_unixtime(BEGIN_TIME, 'dd-MMM-yyyy HH') as qdatehour, sum(price)\n",
    "from my_table2\n",
    "where product = 'Milk'\n",
    "group by from_unixtime(BEGIN_TIME, 'dd-MMM-yyyy HH')\n",
    "\n",
    "order by qdatehour\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Notes:\n",
    "\n",
    "    1- Spark automatically converts unix time to local time, but Impala needs conversion to local time first (+3.5 hours)\n",
    "    \n",
    "    2- In Spark the alias cannot be used in `GROUP BY`, but in Impala it is possible.\n",
    "    \n",
    "    3- When using `UNION` place `ORDER BY` at the end of script\n",
    "    \n",
    "    4- If alias used, `ORDER BY` of multiple statements must be the alias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minutes Granularity\n",
    "\n",
    "15 minutes example:\n",
    "\n",
    "**Impala:**\n",
    "\n",
    "```sql\n",
    "SELECT from_unixtime(floor((begin_time + 7*1800)/900)*900, 'dd-MMM-yyyy HH:mm') as qdatehour, sum(price)\n",
    "from my_table\n",
    "where product = 'Milk'\n",
    "group by qdatehour\n",
    "```\n",
    "\n",
    "**Spark:**\n",
    "\n",
    "```sql\n",
    "SELECT from_unixtime(floor(begin_time/900)*900, 'dd-MMM-yyyy HH:mm') as qdatehour, sum(price)\n",
    "from my_table\n",
    "where product = 'Milk'\n",
    "group by from_unixtime(floor(begin_time/900)*900, 'dd-MMM-yyyy HH:mm')\n",
    "```\n",
    "\n",
    "\n",
    "Notes:\n",
    "\n",
    "    1- Spark automatically converts unix time to local time, but Impala needs conversion to local time first (+3.5 hours)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Functions\n",
    "\n",
    "substring\n",
    "\n",
    "**Impala:**\n",
    "```sql\n",
    "strleft(purcahse_date, 4) as purchase_year\n",
    "```\n",
    "\n",
    "**Spark:**\n",
    "```sql\n",
    "substr(purcahse_date, 1, 8) as purchase_year\n",
    "\n",
    "\n",
    "SELECT CONCAT(\"SQL \", \"Tutorial \", \"is \", \"fun!\") AS ConcatenatedString;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Functions\n",
    "\n",
    "\n",
    "\n",
    "**Spark:**\n",
    "```sql\n",
    "SELECT CURRENT_DATE();\n",
    "select CURRENT_TIMESTAMP() \n",
    "select DATEDIFF(CURRENT_DATE(),cast('2021-01-5' as date)) \n",
    "SELECT DATE_ADD(\"2021-01-15\",  3);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Functions\n",
    "\n",
    "**Impala and Spark:**\n",
    "```sql\n",
    "SELECT ROUND(135.375, 2);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Functions Comparison\n",
    "\n",
    "**Impala:**\n",
    "```sql\n",
    "SELECT ISNULL('Salam', 500);\n",
    "```\n",
    "\n",
    "\n",
    "**Spark:**\n",
    "```sql\n",
    "SELECT IFNULL('Salam', 500);\n",
    "\n",
    "SELECT case when 'Salam' is null THEN 500 ELSE 'Salam' END \n",
    "\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "```sql\n",
    "SELECT (case when sum(price) is null THEN 0 ELSE sum(price) END) as Total_price\n",
    "from my_table\n",
    "where product = 'Milk'\n",
    "\n",
    "SELECT (IFNULL(sum(price), 0) ) as Total_price\n",
    "from my_table\n",
    "where product = 'Milk'\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
